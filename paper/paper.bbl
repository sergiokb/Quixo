\begin{thebibliography}{1}

\bibitem{berglund2023reverasal}
Lukas Berglund, Asa~Cooper Stickland, Meg Tong, Max Kaufmann, Mikita Balesni,
  Tomasz Korbak, and Owain Evans.
\newblock The reverasal curse: Llms trained on “a is b” fail to learn “b
  is a”, 2023.
\newblock Available at: \url{https://arxiv.org/pdf/2206.10498}.

\bibitem{guo2024can}
Hongyi Guo, Zhihan Liu, Yufeng Zhang, and Zhaoran Wang.
\newblock Can large language models play games? a case study of a self-play
  approach, 2024.
\newblock Available at: \url{https://arxiv.org/pdf/2402.04494v1}.

\bibitem{ruoss2024gradmaster}
Anian Ruoss, Gregoire Deletang, Sourabh Medapati, Jordi Grau-Moya, Li~Kevin
  Wenliang, Elliot Catt, John Reid, and Tim Genewein.
\newblock Gradmaster-level chess without search, 2024.
\newblock Available at: \url{https://arxiv.org/pdf/2402.04494v1}.

\bibitem{tanak2020quixo}
Satoshi Tanak, Francois Bonnet, Sebastien Tixeuil, and Yasumasa Tamura.
\newblock Quixo is solved, 2020.
\newblock Available at: \url{https://arxiv.org/pdf/2007.15895}.

\bibitem{valmeekam2023planbench}
Karthik Valmeekam, Matthew Marquez, Alberto Olmo, Sarath Sreedharan, and
  Subbarao Kambhampati.
\newblock Planbench: An extensible benchmark for evaluating large language
  models on planning and reasoning about change, 2023.
\newblock Available at: \url{https://arxiv.org/pdf/2206.10498}.

\end{thebibliography}
